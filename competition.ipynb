{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloads all Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is commented out because it's already been done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100 25483  100 25483    0     0  76784      0 --:--:-- --:--:-- --:--:-- 77455\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100 49968  100 49968    0     0   172k      0 --:--:-- --:--:-- --:--:--  173k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100  8120  100  8120    0     0  35924      0 --:--:-- --:--:-- --:--:-- 36088\n",
      "100  8120  100  8120    0     0  35903      0 --:--:-- --:--:-- --:--:-- 36088\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  3  808k    3 32768    0     0  35436      0  0:00:23 --:--:--  0:00:23 35463\n",
      "100  808k  100  808k    0     0   645k      0  0:00:01  0:00:01 --:--:--  647k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100  269k  100  269k    0     0   565k      0 --:--:-- --:--:-- --:--:--  567k\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "!curl -o helper_functions.py https://raw.githubusercontent.com/jakesanghavi/TDP_March_Tournament_2025/main/helper_functions.py\n",
    "!curl -o logos.csv https://raw.githubusercontent.com/jakesanghavi/TDP_March_Tournament_2025/main/logos.csv\n",
    "!curl -o ncaa_name_mapper.csv https://raw.githubusercontent.com/jakesanghavi/TDP_March_Tournament_2025/main/ncaa_name_mapper.csv\n",
    "!curl -o tournament_data.csv https://raw.githubusercontent.com/jakesanghavi/TDP_March_Tournament_2025/main/tournament_data.csv\n",
    "!curl -o Arial.ttf https://raw.githubusercontent.com/jakesanghavi/TDP_March_Tournament_2025/main/Arial.ttf\"\n",
    "\"\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load in Helper Functions and Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import *\n",
    "import pandas as pd\n",
    "#import sweetviz as sv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start off by reading in the data, and get started with your modeling!\n",
    "data = pd.read_csv('tournament_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function that gets the column names that are not written like the rest\n",
    "def wrong_name(x):\n",
    "    bad=[]\n",
    "    for f in x:\n",
    "        if not (f.startswith('Team')):\n",
    "            bad.append(f)\n",
    "    return bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Season',\n",
       " 'Round',\n",
       " 'RegionTeamA',\n",
       " 'RegionTeamB',\n",
       " 'SeedTeamA',\n",
       " 'SeedTeamB',\n",
       " 'ScoreTeamA',\n",
       " 'ScoreTeamB',\n",
       " 'TotG',\n",
       " 'TotW',\n",
       " 'TotL',\n",
       " 'NeutralG',\n",
       " 'WinPct',\n",
       " 'TotG.1',\n",
       " 'TotW.1',\n",
       " 'TotL.1',\n",
       " 'NeutralG.1',\n",
       " 'WinPct.1',\n",
       " 'ResultTeamA']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "og_columns=list(data.columns)\n",
    "wrong_name(og_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Season', 'Round']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rename undesired columns\n",
    "column_rename={'RegionTeamA':'TeamA_Region','RegionTeamB':'TeamB_Region','SeedTeamA':'TeamA_Seed',\n",
    "               'SeedTeamB':'TeamB_Seed','ScoreTeamA':'TeamA_Score','ScoreTeamB':'TeamB_Score','TotG':'TeamA_TotG','TotW':'TeamA_TotW',\n",
    "               'TotL':'TeamA_TotL','NeutralG':'TeamA_NeutralG','WinPct':'TeamA_WinPct','TotG.1':'TeamB_TotG','TotW.1':'TeamB_TotW',\n",
    "               'TotL.1':'TeamB_TotL','NeutralG.1':'TeamB_NeutralG','WinPct.1':'TeamB_WinPct','ResultTeamA':'TeamA_Result'}\n",
    "data.rename(column_rename,axis=1,inplace=True)\n",
    "#double check that columns are renamed. Only outputs should be Season and Round\n",
    "wrong_name(list(data.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nauto_report = sv.analyze(data,\\'TeamA_Result\\')\\nauto_report.show_html()\"\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#autoviz graph report\n",
    "#commented out because, the html file has already been generated\n",
    "\"\"\"\n",
    "auto_report = sv.analyze(data,'TeamA_Result')\n",
    "auto_report.show_html()\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Takeaways from Initial Graphs\n",
    "Columns that matter: Round -team A always wins at round 0,\n",
    "\n",
    "\n",
    "Doesn't matter: Season, TeamA_Region, TeamB_Region, TeamB\n",
    "\n",
    "\n",
    "Potentially useful: TeamA (don't include TeamB since it would be overfitting), TeamA_Seed and TeamB_Seed(high correlation with round)\n",
    "\n",
    "\n",
    "Highest absolute correlation with target column: \n",
    "TeamB_Seed              0.174414\n",
    "\n",
    "TeamB_HomeW            -0.136270\n",
    "\n",
    "TeamB_NeutralL         -0.111010\n",
    "\n",
    "TeamB_TotBlk           -0.100748\n",
    "\n",
    "TeamB_TotFGM           -0.097671\n",
    "\n",
    "TeamB_AwayL             0.097506\n",
    "\n",
    "TeamB_AvgTotBlk        -0.090055\n",
    "\n",
    "TeamB_TotFGA           -0.089728\n",
    "\n",
    "TeamB_TotAst           -0.089327\n",
    "\n",
    "TeamA_AvgTotOppStl     -0.085053\n",
    "\n",
    "TeamB_TotScore         -0.081266\n",
    "\n",
    "TeamA_TotW              0.077743\n",
    "\n",
    "TeamB_TotStl           -0.076735\n",
    "\n",
    "TeamA_WinPct            0.075789\n",
    "\n",
    "TeamA_AwayW             0.074285\n",
    "\n",
    "TeamB_AvgTotFGM        -0.071465\n",
    "\n",
    "TeamA_AvgTotOppAst     -0.070850\n",
    "\n",
    "TeamB_TotG.1           -0.070380\n",
    "\n",
    "TeamA_AvgTotTO         -0.070164\n",
    "\n",
    "TeamA_TotL             -0.069718\n",
    "\n",
    "Round                  -0.069691\n",
    "\n",
    "TeamA_NeutralL         -0.069198\n",
    "\n",
    "TeamB_TotW.1           -0.068959\n",
    "\n",
    "TeamA_AvgTotOppScore   -0.068904\n",
    "\n",
    "TeamA_TotOppStl        -0.067962\n",
    "\n",
    "TeamA_NeutralW          0.066970\n",
    "\n",
    "TeamB_TotOR            -0.066170\n",
    "\n",
    "TeamB_TotOppBlk        -0.063248\n",
    "\n",
    "TeamB_AvgTotAst        -0.063244\n",
    "\n",
    "TeamA_HomeL            -0.061691\n",
    "\n",
    "TeamB_AvgTotFGA        -0.059754\n",
    "\n",
    "TeamA_AvgTotOppFGM3    -0.057773\n",
    "\n",
    "TeamB_TotOppFGA        -0.056366\n",
    "\n",
    "TeamB_TotOppAst        -0.055578\n",
    "\n",
    "TeamB_NeutralG.1       -0.054396\n",
    "\n",
    "TeamB_AvgTotStl        -0.054200\n",
    "\n",
    "TeamB_TotDR            -0.053619\n",
    "\n",
    "TeamB_TotOppFGA3       -0.053285\n",
    "\n",
    "TeamA_AvgTotPF         -0.053174\n",
    "\n",
    "TeamA_AvgTotOppFGA3    -0.052860\n",
    "\n",
    "TeamA_AvgTotOppFTM     -0.052099\n",
    "\n",
    "TeamA_AvgTotOppBlk     -0.051065\n",
    "\n",
    "TeamA_TotTO            -0.050772\n",
    "\n",
    "TeamA_TotOppAst        -0.050326\n",
    "\n",
    "TeamA_AvgTotOppFGA     -0.050140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cohen\\AppData\\Local\\Temp\\ipykernel_27000\\3892363644.py:1: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  target_corrs=abs(data.corr()['TeamA_Result'])\n",
      "C:\\Users\\cohen\\AppData\\Local\\Temp\\ipykernel_27000\\3892363644.py:3: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  data.corr()['TeamA_Result'].loc[above5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TeamA_Result            1.000000\n",
       "TeamB_Score            -0.439804\n",
       "TeamA_Score             0.304295\n",
       "TeamB_Seed              0.174414\n",
       "TeamB_HomeW            -0.136270\n",
       "TeamB_NeutralL         -0.111010\n",
       "TeamB_TotBlk           -0.100748\n",
       "TeamB_TotFGM           -0.097671\n",
       "TeamB_AwayL             0.097506\n",
       "TeamB_AvgTotBlk        -0.090055\n",
       "TeamB_TotFGA           -0.089728\n",
       "TeamB_TotAst           -0.089327\n",
       "TeamA_AvgTotOppStl     -0.085053\n",
       "TeamB_TotScore         -0.081266\n",
       "TeamA_TotW              0.077743\n",
       "TeamB_TotStl           -0.076735\n",
       "TeamA_WinPct            0.075789\n",
       "TeamA_AwayW             0.074285\n",
       "TeamB_AvgTotFGM        -0.071465\n",
       "TeamA_AvgTotOppAst     -0.070850\n",
       "TeamB_TotG.1           -0.070380\n",
       "TeamA_AvgTotTO         -0.070164\n",
       "TeamA_TotL             -0.069718\n",
       "Round                  -0.069691\n",
       "TeamA_NeutralL         -0.069198\n",
       "TeamB_TotW.1           -0.068959\n",
       "TeamA_AvgTotOppScore   -0.068904\n",
       "TeamA_TotOppStl        -0.067962\n",
       "TeamA_NeutralW          0.066970\n",
       "TeamB_TotOR            -0.066170\n",
       "TeamB_TotOppBlk        -0.063248\n",
       "TeamB_AvgTotAst        -0.063244\n",
       "TeamA_HomeL            -0.061691\n",
       "TeamB_AvgTotFGA        -0.059754\n",
       "TeamA_AvgTotOppFGM3    -0.057773\n",
       "TeamB_TotOppFGA        -0.056366\n",
       "TeamB_TotOppAst        -0.055578\n",
       "TeamB_NeutralG.1       -0.054396\n",
       "TeamB_AvgTotStl        -0.054200\n",
       "TeamB_TotDR            -0.053619\n",
       "TeamB_TotOppFGA3       -0.053285\n",
       "TeamA_AvgTotPF         -0.053174\n",
       "TeamA_AvgTotOppFGA3    -0.052860\n",
       "TeamA_AvgTotOppFTM     -0.052099\n",
       "TeamA_AvgTotOppBlk     -0.051065\n",
       "TeamA_TotTO            -0.050772\n",
       "TeamA_TotOppAst        -0.050326\n",
       "TeamA_AvgTotOppFGA     -0.050140\n",
       "Name: TeamA_Result, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_corrs=abs(data.corr()['TeamA_Result'])\n",
    "above5=target_corrs[target_corrs >0.05].sort_values(ascending=False).index\n",
    "data.corr()['TeamA_Result'].loc[above5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove TeamA_Score and TeamB_Score since these columns we can't use as features in our analysis\n",
    "#also removing region columns, since we have seen in our eda that it has no effect on our target variable\n",
    "df=data.copy()\n",
    "df.drop(['TeamA_Score','TeamB_Score','TeamA_Region','TeamB_Region'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cohen\\AppData\\Local\\Temp\\ipykernel_22020\\4294890134.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[diff_name]=df[a_feature]-df[b_feature]\n",
      "C:\\Users\\cohen\\AppData\\Local\\Temp\\ipykernel_22020\\4294890134.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[diff_name]=df[a_feature]-df[b_feature]\n",
      "C:\\Users\\cohen\\AppData\\Local\\Temp\\ipykernel_22020\\4294890134.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[diff_name]=df[a_feature]-df[b_feature]\n",
      "C:\\Users\\cohen\\AppData\\Local\\Temp\\ipykernel_22020\\4294890134.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[diff_name]=df[a_feature]-df[b_feature]\n",
      "C:\\Users\\cohen\\AppData\\Local\\Temp\\ipykernel_22020\\4294890134.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[diff_name]=df[a_feature]-df[b_feature]\n",
      "C:\\Users\\cohen\\AppData\\Local\\Temp\\ipykernel_22020\\4294890134.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[diff_name]=df[a_feature]-df[b_feature]\n",
      "C:\\Users\\cohen\\AppData\\Local\\Temp\\ipykernel_22020\\4294890134.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[diff_name]=df[a_feature]-df[b_feature]\n",
      "C:\\Users\\cohen\\AppData\\Local\\Temp\\ipykernel_22020\\4294890134.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[diff_name]=df[a_feature]-df[b_feature]\n",
      "C:\\Users\\cohen\\AppData\\Local\\Temp\\ipykernel_22020\\4294890134.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[diff_name]=df[a_feature]-df[b_feature]\n",
      "C:\\Users\\cohen\\AppData\\Local\\Temp\\ipykernel_22020\\4294890134.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[diff_name]=df[a_feature]-df[b_feature]\n",
      "C:\\Users\\cohen\\AppData\\Local\\Temp\\ipykernel_22020\\4294890134.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[diff_name]=df[a_feature]-df[b_feature]\n",
      "C:\\Users\\cohen\\AppData\\Local\\Temp\\ipykernel_22020\\4294890134.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[diff_name]=df[a_feature]-df[b_feature]\n",
      "C:\\Users\\cohen\\AppData\\Local\\Temp\\ipykernel_22020\\4294890134.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[diff_name]=df[a_feature]-df[b_feature]\n",
      "C:\\Users\\cohen\\AppData\\Local\\Temp\\ipykernel_22020\\4294890134.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[diff_name]=df[a_feature]-df[b_feature]\n",
      "C:\\Users\\cohen\\AppData\\Local\\Temp\\ipykernel_22020\\4294890134.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[diff_name]=df[a_feature]-df[b_feature]\n",
      "C:\\Users\\cohen\\AppData\\Local\\Temp\\ipykernel_22020\\4294890134.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[diff_name]=df[a_feature]-df[b_feature]\n",
      "C:\\Users\\cohen\\AppData\\Local\\Temp\\ipykernel_22020\\4294890134.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[diff_name]=df[a_feature]-df[b_feature]\n",
      "C:\\Users\\cohen\\AppData\\Local\\Temp\\ipykernel_22020\\4294890134.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[diff_name]=df[a_feature]-df[b_feature]\n",
      "C:\\Users\\cohen\\AppData\\Local\\Temp\\ipykernel_22020\\4294890134.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[diff_name]=df[a_feature]-df[b_feature]\n",
      "C:\\Users\\cohen\\AppData\\Local\\Temp\\ipykernel_22020\\4294890134.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[diff_name]=df[a_feature]-df[b_feature]\n",
      "C:\\Users\\cohen\\AppData\\Local\\Temp\\ipykernel_22020\\4294890134.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[diff_name]=df[a_feature]-df[b_feature]\n",
      "C:\\Users\\cohen\\AppData\\Local\\Temp\\ipykernel_22020\\4294890134.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[diff_name]=df[a_feature]-df[b_feature]\n",
      "C:\\Users\\cohen\\AppData\\Local\\Temp\\ipykernel_22020\\4294890134.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[diff_name]=df[a_feature]-df[b_feature]\n",
      "C:\\Users\\cohen\\AppData\\Local\\Temp\\ipykernel_22020\\4294890134.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[diff_name]=df[a_feature]-df[b_feature]\n",
      "C:\\Users\\cohen\\AppData\\Local\\Temp\\ipykernel_22020\\4294890134.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[diff_name]=df[a_feature]-df[b_feature]\n",
      "C:\\Users\\cohen\\AppData\\Local\\Temp\\ipykernel_22020\\4294890134.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[diff_name]=df[a_feature]-df[b_feature]\n",
      "C:\\Users\\cohen\\AppData\\Local\\Temp\\ipykernel_22020\\4294890134.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[diff_name]=df[a_feature]-df[b_feature]\n",
      "C:\\Users\\cohen\\AppData\\Local\\Temp\\ipykernel_22020\\4294890134.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[diff_name]=df[a_feature]-df[b_feature]\n",
      "C:\\Users\\cohen\\AppData\\Local\\Temp\\ipykernel_22020\\4294890134.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[diff_name]=df[a_feature]-df[b_feature]\n",
      "C:\\Users\\cohen\\AppData\\Local\\Temp\\ipykernel_22020\\4294890134.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[diff_name]=df[a_feature]-df[b_feature]\n",
      "C:\\Users\\cohen\\AppData\\Local\\Temp\\ipykernel_22020\\4294890134.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[diff_name]=df[a_feature]-df[b_feature]\n",
      "C:\\Users\\cohen\\AppData\\Local\\Temp\\ipykernel_22020\\4294890134.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[diff_name]=df[a_feature]-df[b_feature]\n",
      "C:\\Users\\cohen\\AppData\\Local\\Temp\\ipykernel_22020\\4294890134.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[diff_name]=df[a_feature]-df[b_feature]\n",
      "C:\\Users\\cohen\\AppData\\Local\\Temp\\ipykernel_22020\\4294890134.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[diff_name]=df[a_feature]-df[b_feature]\n",
      "C:\\Users\\cohen\\AppData\\Local\\Temp\\ipykernel_22020\\4294890134.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[diff_name]=df[a_feature]-df[b_feature]\n",
      "C:\\Users\\cohen\\AppData\\Local\\Temp\\ipykernel_22020\\4294890134.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[diff_name]=df[a_feature]-df[b_feature]\n",
      "C:\\Users\\cohen\\AppData\\Local\\Temp\\ipykernel_22020\\4294890134.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[diff_name]=df[a_feature]-df[b_feature]\n",
      "C:\\Users\\cohen\\AppData\\Local\\Temp\\ipykernel_22020\\4294890134.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[diff_name]=df[a_feature]-df[b_feature]\n",
      "C:\\Users\\cohen\\AppData\\Local\\Temp\\ipykernel_22020\\4294890134.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[diff_name]=df[a_feature]-df[b_feature]\n"
     ]
    }
   ],
   "source": [
    "#get a list of columns that have values for team a and team b\n",
    "#remove TeamA_Result column, since that's our target variable\n",
    "df_column=pd.DataFrame({'Columns':df.columns})\n",
    "df_column=df_column[(df_column['Columns'].str.contains('TeamA_'))&(~df_column['Columns'].str.contains('TeamA_Result'))]\n",
    "#create team a to team b ratios for all columns\n",
    "for x in df_column.Columns.values:\n",
    "    feature=x.split('_')[1]\n",
    "    a_feature='TeamA_'+feature\n",
    "    b_feature='TeamB_'+feature\n",
    "    ratio_name=feature+'_ratio'\n",
    "    diff_name=feature+'_diff'\n",
    "    df[ratio_name]=df[a_feature]/df[b_feature]\n",
    "    df[diff_name]=df[a_feature]-df[b_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_finder(x):\n",
    "    return df[x].corr(df['TeamA_Result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>TeamA_Corr</th>\n",
       "      <th>TeamB_Corr</th>\n",
       "      <th>Ratio_Corr</th>\n",
       "      <th>Dif_Corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TotScore</td>\n",
       "      <td>0.042207</td>\n",
       "      <td>-0.081266</td>\n",
       "      <td>0.115311</td>\n",
       "      <td>0.107028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TotFGM</td>\n",
       "      <td>0.048167</td>\n",
       "      <td>-0.097671</td>\n",
       "      <td>0.130128</td>\n",
       "      <td>0.122367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TotFGA</td>\n",
       "      <td>0.028698</td>\n",
       "      <td>-0.089728</td>\n",
       "      <td>0.106867</td>\n",
       "      <td>0.103745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TotFGM3</td>\n",
       "      <td>0.046281</td>\n",
       "      <td>-0.025056</td>\n",
       "      <td>0.051646</td>\n",
       "      <td>0.056764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TotFGA3</td>\n",
       "      <td>0.038804</td>\n",
       "      <td>-0.032541</td>\n",
       "      <td>0.054224</td>\n",
       "      <td>0.059320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TotOR</td>\n",
       "      <td>0.023990</td>\n",
       "      <td>-0.066170</td>\n",
       "      <td>0.074588</td>\n",
       "      <td>0.076664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>TotOppTO</td>\n",
       "      <td>0.034763</td>\n",
       "      <td>-0.049026</td>\n",
       "      <td>0.065575</td>\n",
       "      <td>0.067271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>TotG</td>\n",
       "      <td>0.034247</td>\n",
       "      <td>-0.070380</td>\n",
       "      <td>0.107376</td>\n",
       "      <td>0.112278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>TotW</td>\n",
       "      <td>0.077743</td>\n",
       "      <td>-0.068959</td>\n",
       "      <td>0.124137</td>\n",
       "      <td>0.121096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>WinPct</td>\n",
       "      <td>0.075789</td>\n",
       "      <td>-0.039142</td>\n",
       "      <td>0.088295</td>\n",
       "      <td>0.087162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>AvgTotScore</td>\n",
       "      <td>0.030865</td>\n",
       "      <td>-0.045997</td>\n",
       "      <td>0.062747</td>\n",
       "      <td>0.056911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>AvgTotFGM</td>\n",
       "      <td>0.038069</td>\n",
       "      <td>-0.071465</td>\n",
       "      <td>0.084955</td>\n",
       "      <td>0.081450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>AvgTotFTM</td>\n",
       "      <td>-0.028840</td>\n",
       "      <td>0.023172</td>\n",
       "      <td>-0.030390</td>\n",
       "      <td>-0.039253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>AvgTotFTA</td>\n",
       "      <td>-0.037635</td>\n",
       "      <td>0.029175</td>\n",
       "      <td>-0.043971</td>\n",
       "      <td>-0.052426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>AvgTotTO</td>\n",
       "      <td>-0.070164</td>\n",
       "      <td>0.036316</td>\n",
       "      <td>-0.081375</td>\n",
       "      <td>-0.089939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>AvgTotPF</td>\n",
       "      <td>-0.053174</td>\n",
       "      <td>0.039998</td>\n",
       "      <td>-0.067701</td>\n",
       "      <td>-0.068663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>AvgTotOppScore</td>\n",
       "      <td>-0.068904</td>\n",
       "      <td>0.033737</td>\n",
       "      <td>-0.073270</td>\n",
       "      <td>-0.077871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>AvgTotOppFGM</td>\n",
       "      <td>-0.042699</td>\n",
       "      <td>0.029287</td>\n",
       "      <td>-0.050486</td>\n",
       "      <td>-0.052580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>AvgTotOppFTM</td>\n",
       "      <td>-0.052099</td>\n",
       "      <td>0.022851</td>\n",
       "      <td>-0.054402</td>\n",
       "      <td>-0.054347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>AvgTotOppFTA</td>\n",
       "      <td>-0.046084</td>\n",
       "      <td>0.028943</td>\n",
       "      <td>-0.052421</td>\n",
       "      <td>-0.054906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>AvgTotOppDR</td>\n",
       "      <td>-0.048665</td>\n",
       "      <td>0.040645</td>\n",
       "      <td>-0.069194</td>\n",
       "      <td>-0.068533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>AvgTotOppTO</td>\n",
       "      <td>0.023217</td>\n",
       "      <td>-0.020539</td>\n",
       "      <td>0.028799</td>\n",
       "      <td>0.035850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>AvgTotOppPF</td>\n",
       "      <td>-0.040500</td>\n",
       "      <td>0.030984</td>\n",
       "      <td>-0.051414</td>\n",
       "      <td>-0.056578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Feature  TeamA_Corr  TeamB_Corr  Ratio_Corr  Dif_Corr\n",
       "1         TotScore    0.042207   -0.081266    0.115311  0.107028\n",
       "2           TotFGM    0.048167   -0.097671    0.130128  0.122367\n",
       "3           TotFGA    0.028698   -0.089728    0.106867  0.103745\n",
       "4          TotFGM3    0.046281   -0.025056    0.051646  0.056764\n",
       "5          TotFGA3    0.038804   -0.032541    0.054224  0.059320\n",
       "8            TotOR    0.023990   -0.066170    0.074588  0.076664\n",
       "31        TotOppTO    0.034763   -0.049026    0.065575  0.067271\n",
       "35            TotG    0.034247   -0.070380    0.107376  0.112278\n",
       "36            TotW    0.077743   -0.068959    0.124137  0.121096\n",
       "39          WinPct    0.075789   -0.039142    0.088295  0.087162\n",
       "40     AvgTotScore    0.030865   -0.045997    0.062747  0.056911\n",
       "41       AvgTotFGM    0.038069   -0.071465    0.084955  0.081450\n",
       "45       AvgTotFTM   -0.028840    0.023172   -0.030390 -0.039253\n",
       "46       AvgTotFTA   -0.037635    0.029175   -0.043971 -0.052426\n",
       "50        AvgTotTO   -0.070164    0.036316   -0.081375 -0.089939\n",
       "53        AvgTotPF   -0.053174    0.039998   -0.067701 -0.068663\n",
       "54  AvgTotOppScore   -0.068904    0.033737   -0.073270 -0.077871\n",
       "55    AvgTotOppFGM   -0.042699    0.029287   -0.050486 -0.052580\n",
       "59    AvgTotOppFTM   -0.052099    0.022851   -0.054402 -0.054347\n",
       "60    AvgTotOppFTA   -0.046084    0.028943   -0.052421 -0.054906\n",
       "62     AvgTotOppDR   -0.048665    0.040645   -0.069194 -0.068533\n",
       "64     AvgTotOppTO    0.023217   -0.020539    0.028799  0.035850\n",
       "67     AvgTotOppPF   -0.040500    0.030984   -0.051414 -0.056578"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find columns where the ratio has a higher correlation with the target variable\n",
    "corr_dict={}\n",
    "#create lists to store feature names and correlations\n",
    "#feature=[]\n",
    "#teama_corr=[]\n",
    "#teamb_corr=[]\n",
    "#ratio_corr=[]\n",
    "#for each feature, get the correlation between the feature and the target variable\n",
    "for x in df_column.Columns.values:\n",
    "    feat=x.split('_')[1]\n",
    "    #feature.append(feat)\n",
    "    a_feature='TeamA_'+feat\n",
    "    a_corr=corr_finder(a_feature)\n",
    "    #teama_corr.append(a_corr)\n",
    "    b_feature='TeamB_'+feat\n",
    "    b_corr=corr_finder(b_feature)\n",
    "    #teamb_corr.append(b_corr)\n",
    "    ratio_name=feat+'_ratio'\n",
    "    rat_cor=corr_finder(ratio_name)\n",
    "    #ratio_corr.append(rat_cor)\n",
    "    dif_name=feat+'_diff'\n",
    "    dif_cor=corr_finder(dif_name)\n",
    "    corr_dict[feat]=[a_corr,b_corr,rat_cor,dif_cor]\n",
    "#put the correlations in a dataframe\n",
    "#corr_dict={'feature_name':feature,'TeamA_Corr':teama_corr,'TeamB_Corr':teamb_corr,'Ratio_Corr':ratio_corr}\n",
    "df_corrs=pd.DataFrame.from_dict(corr_dict,orient='index').reset_index()\n",
    "df_corrs.rename({'index':'Feature',0:'TeamA_Corr',1:'TeamB_Corr',2:'Ratio_Corr',3:'Dif_Corr'},axis=1,inplace=True)\n",
    "#find where the ratio has a higher correlation with the target variable\n",
    "analysis_columns={}\n",
    "df_corrs[(abs(df_corrs['Ratio_Corr'])>abs(df_corrs['TeamA_Corr']))&(abs(df_corrs['Ratio_Corr'])>abs(df_corrs['TeamB_Corr']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>TeamA_Corr</th>\n",
       "      <th>TeamB_Corr</th>\n",
       "      <th>Ratio_Corr</th>\n",
       "      <th>Dif_Corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TotFGM3</td>\n",
       "      <td>0.046281</td>\n",
       "      <td>-0.025056</td>\n",
       "      <td>0.051646</td>\n",
       "      <td>0.056764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TotFGA3</td>\n",
       "      <td>0.038804</td>\n",
       "      <td>-0.032541</td>\n",
       "      <td>0.054224</td>\n",
       "      <td>0.059320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TotOR</td>\n",
       "      <td>0.023990</td>\n",
       "      <td>-0.066170</td>\n",
       "      <td>0.074588</td>\n",
       "      <td>0.076664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>TotOppTO</td>\n",
       "      <td>0.034763</td>\n",
       "      <td>-0.049026</td>\n",
       "      <td>0.065575</td>\n",
       "      <td>0.067271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>TotG</td>\n",
       "      <td>0.034247</td>\n",
       "      <td>-0.070380</td>\n",
       "      <td>0.107376</td>\n",
       "      <td>0.112278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>AvgTotFTM</td>\n",
       "      <td>-0.028840</td>\n",
       "      <td>0.023172</td>\n",
       "      <td>-0.030390</td>\n",
       "      <td>-0.039253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>AvgTotFTA</td>\n",
       "      <td>-0.037635</td>\n",
       "      <td>0.029175</td>\n",
       "      <td>-0.043971</td>\n",
       "      <td>-0.052426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>AvgTotOR</td>\n",
       "      <td>0.011947</td>\n",
       "      <td>-0.045233</td>\n",
       "      <td>0.044497</td>\n",
       "      <td>0.047744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>AvgTotTO</td>\n",
       "      <td>-0.070164</td>\n",
       "      <td>0.036316</td>\n",
       "      <td>-0.081375</td>\n",
       "      <td>-0.089939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>AvgTotPF</td>\n",
       "      <td>-0.053174</td>\n",
       "      <td>0.039998</td>\n",
       "      <td>-0.067701</td>\n",
       "      <td>-0.068663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>AvgTotOppScore</td>\n",
       "      <td>-0.068904</td>\n",
       "      <td>0.033737</td>\n",
       "      <td>-0.073270</td>\n",
       "      <td>-0.077871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>AvgTotOppFGM</td>\n",
       "      <td>-0.042699</td>\n",
       "      <td>0.029287</td>\n",
       "      <td>-0.050486</td>\n",
       "      <td>-0.052580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>AvgTotOppFTA</td>\n",
       "      <td>-0.046084</td>\n",
       "      <td>0.028943</td>\n",
       "      <td>-0.052421</td>\n",
       "      <td>-0.054906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>AvgTotOppTO</td>\n",
       "      <td>0.023217</td>\n",
       "      <td>-0.020539</td>\n",
       "      <td>0.028799</td>\n",
       "      <td>0.035850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>AvgTotOppPF</td>\n",
       "      <td>-0.040500</td>\n",
       "      <td>0.030984</td>\n",
       "      <td>-0.051414</td>\n",
       "      <td>-0.056578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Feature  TeamA_Corr  TeamB_Corr  Ratio_Corr  Dif_Corr\n",
       "4          TotFGM3    0.046281   -0.025056    0.051646  0.056764\n",
       "5          TotFGA3    0.038804   -0.032541    0.054224  0.059320\n",
       "8            TotOR    0.023990   -0.066170    0.074588  0.076664\n",
       "31        TotOppTO    0.034763   -0.049026    0.065575  0.067271\n",
       "35            TotG    0.034247   -0.070380    0.107376  0.112278\n",
       "45       AvgTotFTM   -0.028840    0.023172   -0.030390 -0.039253\n",
       "46       AvgTotFTA   -0.037635    0.029175   -0.043971 -0.052426\n",
       "47        AvgTotOR    0.011947   -0.045233    0.044497  0.047744\n",
       "50        AvgTotTO   -0.070164    0.036316   -0.081375 -0.089939\n",
       "53        AvgTotPF   -0.053174    0.039998   -0.067701 -0.068663\n",
       "54  AvgTotOppScore   -0.068904    0.033737   -0.073270 -0.077871\n",
       "55    AvgTotOppFGM   -0.042699    0.029287   -0.050486 -0.052580\n",
       "60    AvgTotOppFTA   -0.046084    0.028943   -0.052421 -0.054906\n",
       "64     AvgTotOppTO    0.023217   -0.020539    0.028799  0.035850\n",
       "67     AvgTotOppPF   -0.040500    0.030984   -0.051414 -0.056578"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find where the ratio has a higher correlation than difference and normal columns\n",
    "analysis_columns['Ratio']=list(df_corrs[(abs(df_corrs['Ratio_Corr'])>abs(df_corrs['TeamA_Corr']))&(abs(df_corrs['Ratio_Corr'])>abs(df_corrs['TeamB_Corr']))&(abs(df_corrs['Ratio_Corr'])>abs(df_corrs['Dif_Corr']))]['Feature'])\n",
    "#df_corrs[(abs(df_corrs['Ratio_Corr'])>abs(df_corrs['TeamA_Corr']))&(abs(df_corrs['Ratio_Corr'])>abs(df_corrs['TeamB_Corr']))&(abs(df_corrs['Ratio_Corr'])>abs(df_corrs['Dif_Corr']))]\n",
    "#find where the difference has higher correlation than the ratio\n",
    "analysis_columns['Dif']=list(df_corrs[(abs(df_corrs['Dif_Corr'])>abs(df_corrs['Ratio_Corr']))&(abs(df_corrs['Dif_Corr'])>abs(df_corrs['TeamB_Corr']))&(abs(df_corrs['Dif_Corr'])>abs(df_corrs['TeamA_Corr']))]['Feature'])\n",
    "#df_corrs[(abs(df_corrs['Dif_Corr'])>abs(df_corrs['Ratio_Corr']))&(abs(df_corrs['Dif_Corr'])>abs(df_corrs['TeamB_Corr']))&(abs(df_corrs['Dif_Corr'])>abs(df_corrs['TeamA_Corr']))]\n",
    "analysis_columns['Team']=list(set(df_corrs['Feature'])-set(analysis_columns['Ratio'])-set(analysis_columns['Dif']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a list of only the columns we want for further analysis\n",
    "col_anly=['Round','Season','TeamA','TeamB']\n",
    "for x in analysis_columns['Team']:\n",
    "    col_anly.append('TeamA_'+x)\n",
    "    col_anly.append('TeamB_'+x)\n",
    "for x in analysis_columns['Dif']:\n",
    "    col_anly.append(x+'_diff')\n",
    "    col_anly.append(x+'_ratio')\n",
    "for x in analysis_columns['Ratio']:\n",
    "    col_anly.append(x+'_ratio')\n",
    "#including the difference between seed because it's correlation is almost as high as TeamB_Corr, and it makes sense intuitively\n",
    "col_anly.append('Seed_diff')\n",
    "col_anly.append('TeamA_Result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cohen\\AppData\\Local\\Temp\\ipykernel_22020\\3466147140.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_analy['Round * TeamA_Seed']=df_analy['Round']*df_analy['TeamA_Seed']\n",
      "C:\\Users\\cohen\\AppData\\Local\\Temp\\ipykernel_22020\\3466147140.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_analy['Round * Seed_diff']=df_analy['Round']*df_analy['Seed_diff']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.09577274625949554"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_analy=df[col_anly]\n",
    "#create interaction variable between round and team a seed\n",
    "df_analy['Round * TeamA_Seed']=df_analy['Round']*df_analy['TeamA_Seed']\n",
    "df_analy[\"Round * TeamA_Seed\"].corr(df_analy['TeamA_Result'])\n",
    "df_analy['Round * Seed_diff']=df_analy['Round']*df_analy['Seed_diff']\n",
    "df_analy[\"Round * Seed_diff\"].corr(df_analy['TeamA_Result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "740c3fd15ea848939ced59f5917b555f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "                                             |          | [  0%]   00:00 -> (? left)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cohen\\anaconda3\\envs\\sweetviz\\lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "c:\\Users\\cohen\\anaconda3\\envs\\sweetviz\\lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "c:\\Users\\cohen\\anaconda3\\envs\\sweetviz\\lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "c:\\Users\\cohen\\anaconda3\\envs\\sweetviz\\lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "c:\\Users\\cohen\\anaconda3\\envs\\sweetviz\\lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "c:\\Users\\cohen\\anaconda3\\envs\\sweetviz\\lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "c:\\Users\\cohen\\anaconda3\\envs\\sweetviz\\lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "c:\\Users\\cohen\\anaconda3\\envs\\sweetviz\\lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "c:\\Users\\cohen\\anaconda3\\envs\\sweetviz\\lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "c:\\Users\\cohen\\anaconda3\\envs\\sweetviz\\lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "c:\\Users\\cohen\\anaconda3\\envs\\sweetviz\\lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "c:\\Users\\cohen\\anaconda3\\envs\\sweetviz\\lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "c:\\Users\\cohen\\anaconda3\\envs\\sweetviz\\lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "c:\\Users\\cohen\\anaconda3\\envs\\sweetviz\\lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "c:\\Users\\cohen\\anaconda3\\envs\\sweetviz\\lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "c:\\Users\\cohen\\anaconda3\\envs\\sweetviz\\lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "c:\\Users\\cohen\\anaconda3\\envs\\sweetviz\\lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "c:\\Users\\cohen\\anaconda3\\envs\\sweetviz\\lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "c:\\Users\\cohen\\anaconda3\\envs\\sweetviz\\lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "c:\\Users\\cohen\\anaconda3\\envs\\sweetviz\\lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "c:\\Users\\cohen\\anaconda3\\envs\\sweetviz\\lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "c:\\Users\\cohen\\anaconda3\\envs\\sweetviz\\lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "c:\\Users\\cohen\\anaconda3\\envs\\sweetviz\\lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "c:\\Users\\cohen\\anaconda3\\envs\\sweetviz\\lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "c:\\Users\\cohen\\anaconda3\\envs\\sweetviz\\lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "c:\\Users\\cohen\\anaconda3\\envs\\sweetviz\\lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "c:\\Users\\cohen\\anaconda3\\envs\\sweetviz\\lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "c:\\Users\\cohen\\anaconda3\\envs\\sweetviz\\lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "c:\\Users\\cohen\\anaconda3\\envs\\sweetviz\\lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "c:\\Users\\cohen\\anaconda3\\envs\\sweetviz\\lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "c:\\Users\\cohen\\anaconda3\\envs\\sweetviz\\lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "c:\\Users\\cohen\\anaconda3\\envs\\sweetviz\\lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report SWEETVIZ_REPORT.html was generated! NOTEBOOK/COLAB USERS: the web browser MAY not pop up, regardless, the report IS saved in your notebook/colab files.\n"
     ]
    }
   ],
   "source": [
    "#create new sweetviz graph with selected columns\n",
    "#auto_report = sv.analyze(df_analy,'TeamA_Result')\n",
    "#auto_report.show_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_analy.to_csv('engineered_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import sort\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_analy=df_analy.drop(['TeamA','TeamB'],axis=1)\n",
    "train=df_analy[df_analy['Season']<2024].drop('Season',axis=1)\n",
    "test=df_analy[df_analy['Season']==2024].drop('Season',axis=1)\n",
    "train_x=train.drop('TeamA_Result',axis=1)\n",
    "train_y=train['TeamA_Result']\n",
    "test_x=test.drop('TeamA_Result',axis=1)\n",
    "test_y=test['TeamA_Result']\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(train_x)\n",
    "X_test_scaled = scaler.transform(test_x)\n",
    "model = XGBClassifier(n_estimators=100, max_depth=6, learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on 2024 season: 0.6567\n"
     ]
    }
   ],
   "source": [
    "#fit the model and get accuracy\n",
    "#learning rate 0.1\n",
    "model.fit(X_train_scaled, train_y)\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(test_y, y_pred)\n",
    "\n",
    "print(f\"Accuracy on 2024 season: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'booster' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[183], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mbooster\u001b[49m\u001b[38;5;241m.\u001b[39mget_feature_imoprtance()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'booster' is not defined"
     ]
    }
   ],
   "source": [
    "booster.get_feature_imoprtance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['Round']==0]['TeamA_Result'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'super' object has no attribute '__sklearn_tags__'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[176], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m thresh \u001b[38;5;129;01min\u001b[39;00m thresholds:\n\u001b[0;32m      2\u001b[0m  \u001b[38;5;66;03m# select features using threshold\u001b[39;00m\n\u001b[0;32m      3\u001b[0m  selection \u001b[38;5;241m=\u001b[39m SelectFromModel(model, threshold\u001b[38;5;241m=\u001b[39mthresh, prefit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 4\u001b[0m  select_X_train \u001b[38;5;241m=\u001b[39m \u001b[43mselection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m  \u001b[38;5;66;03m# train model\u001b[39;00m\n\u001b[0;32m      6\u001b[0m  selection_model \u001b[38;5;241m=\u001b[39m XGBClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\cohen\\anaconda3\\envs\\sweetviz\\lib\\site-packages\\sklearn\\utils\\_set_output.py:319\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 319\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    322\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    323\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    324\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    325\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\cohen\\anaconda3\\envs\\sweetviz\\lib\\site-packages\\sklearn\\feature_selection\\_base.py:116\u001b[0m, in \u001b[0;36mSelectorMixin.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;66;03m# note: we use get_tags instead of __sklearn_tags__ because this is a\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;66;03m# public Mixin.\u001b[39;00m\n\u001b[0;32m    107\u001b[0m X \u001b[38;5;241m=\u001b[39m validate_data(\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    109\u001b[0m     X,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    114\u001b[0m     reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    115\u001b[0m )\n\u001b[1;32m--> 116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\cohen\\anaconda3\\envs\\sweetviz\\lib\\site-packages\\sklearn\\feature_selection\\_base.py:120\u001b[0m, in \u001b[0;36mSelectorMixin._transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    119\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Reduce X to the selected features.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 120\u001b[0m     mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_support\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m    122\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    123\u001b[0m             (\n\u001b[0;32m    124\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo features were selected: either the data is\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    127\u001b[0m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[0;32m    128\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\cohen\\anaconda3\\envs\\sweetviz\\lib\\site-packages\\sklearn\\feature_selection\\_base.py:72\u001b[0m, in \u001b[0;36mSelectorMixin.get_support\u001b[1;34m(self, indices)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_support\u001b[39m(\u001b[38;5;28mself\u001b[39m, indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     53\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;124;03m    Get a mask, or integer index, of the features selected.\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m        values are indices into the input feature vector.\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m     mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_support_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mask \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m indices \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39mwhere(mask)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\cohen\\anaconda3\\envs\\sweetviz\\lib\\site-packages\\sklearn\\feature_selection\\_from_model.py:266\u001b[0m, in \u001b[0;36mSelectFromModel._get_support_mask\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprefit:\n\u001b[0;32m    265\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 266\u001b[0m         \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    267\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m NotFittedError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    268\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(\n\u001b[0;32m    269\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen `prefit=True`, `estimator` is expected to be a fitted \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    270\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mestimator.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    271\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\cohen\\anaconda3\\envs\\sweetviz\\lib\\site-packages\\sklearn\\utils\\validation.py:1751\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(estimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not an estimator instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (estimator))\n\u001b[1;32m-> 1751\u001b[0m tags \u001b[38;5;241m=\u001b[39m \u001b[43mget_tags\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1753\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tags\u001b[38;5;241m.\u001b[39mrequires_fit \u001b[38;5;129;01mand\u001b[39;00m attributes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1754\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\cohen\\anaconda3\\envs\\sweetviz\\lib\\site-packages\\sklearn\\utils\\_tags.py:430\u001b[0m, in \u001b[0;36mget_tags\u001b[1;34m(estimator)\u001b[0m\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m klass \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39mmro()):\n\u001b[0;32m    429\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__sklearn_tags__\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(klass):\n\u001b[1;32m--> 430\u001b[0m         sklearn_tags_provider[klass] \u001b[38;5;241m=\u001b[39m \u001b[43mklass\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__sklearn_tags__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    431\u001b[0m         class_order\u001b[38;5;241m.\u001b[39mappend(klass)\n\u001b[0;32m    432\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_more_tags\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(klass):\n",
      "File \u001b[1;32mc:\\Users\\cohen\\anaconda3\\envs\\sweetviz\\lib\\site-packages\\sklearn\\base.py:540\u001b[0m, in \u001b[0;36mClassifierMixin.__sklearn_tags__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__sklearn_tags__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 540\u001b[0m     tags \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__sklearn_tags__\u001b[49m()\n\u001b[0;32m    541\u001b[0m     tags\u001b[38;5;241m.\u001b[39mestimator_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    542\u001b[0m     tags\u001b[38;5;241m.\u001b[39mclassifier_tags \u001b[38;5;241m=\u001b[39m ClassifierTags()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'super' object has no attribute '__sklearn_tags__'"
     ]
    }
   ],
   "source": [
    "for thresh in thresholds:\n",
    " # select features using threshold\n",
    " selection = SelectFromModel(model, threshold=thresh, prefit=True)\n",
    " select_X_train = selection.transform(X_train_scaled)\n",
    " # train model\n",
    " selection_model = XGBClassifier(n_estimators=100, max_depth=6, learning_rate=0.1)\n",
    " selection_model.fit(select_X_train, train_y)\n",
    " # eval model\n",
    " select_X_test = selection.transform(X_test_scaled)\n",
    " predictions = selection_model.predict(select_X_test)\n",
    " accuracy = accuracy_score(test_y, predictions)\n",
    " print(\"Thresh=%.3f, n=%d, Accuracy: %.2f%%\" % (thresh, select_X_train.shape[1], accuracy*100.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Use this as test_Y instead if doing regression'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classification\n",
    "train = data[data['Season'] < 2024].drop(columns=['Season'])\n",
    "train_teams = train[['TeamA', 'TeamB']]\n",
    "train_X = train.drop(columns=['TeamA_Region', 'TeamB_Region', 'TeamA', 'TeamB', 'TeamA_Result', 'TeamA_Score', 'TeamB_Score'])\n",
    "train_Y = train['TeamA_Result']\n",
    "'''Use this instead as train_Y if doing regression'''\n",
    "# train_Y = train[['ScoreTeamA', 'ScoreTeamB']]\n",
    "# Classification\n",
    "test = data[data['Season'] == 2024].drop(columns=['Season'])\n",
    "test_teams = test[['TeamA', 'TeamB']]\n",
    "test_X = test.drop(columns=['TeamA_Region', 'TeamB_Region', 'TeamA', 'TeamB', 'TeamA_Result', 'TeamA_Score', 'TeamB_Score'])\n",
    "test_Y = test['TeamA_Result']\n",
    "\n",
    "'''Use this as test_Y instead if doing regression'''\n",
    "# test_Y = test[['ScoreTeamA', 'ScoreTeamB']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sweetviz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
